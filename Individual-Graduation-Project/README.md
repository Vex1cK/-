# Individual-Graduation-Project
A project in the tenth and eleventh grades of the Lyceum of the Higher School of Economics



# RU description

## Структура проекта

```
Individual-Graduation-Project
├── backend
│   ├── ai_models           # ML модели
│   ├── alembic             # Миграции базы данных
│   ├── src
│   │   ├── auth            # API регистрации-авторизации
│   │   ├── ml_api          # API к ML моделям
│   │   ├── root_router     # Базовые эндпоинты
│   │   ├── static
│   │   └── main.py         # Точка входа в backend приложение
│   ├── tests               # Тесты для API (pytest)
│   ├── Dockerfile
│   ├── .env.example        # Пример переменных окружения в .env файле
│   └── requirements.txt    # Необходимые для работы библиотеки
├── qt_app
│   └── main.py             # Точка входа в QT приложение
└── README.md               # Описание и инструкция
```

## Как запустить бэк

- Клонируйте этот репозиторий к себе на компьютер. Можете сделать это командой `git clone https://github.com/Vex1cK/iBP.git` или скачать архивом и разорхивировать.

*ВАЖНО!*
- Здесь написаны способы поднять бэк *только на localhost*
- бэкенд точно поднимается на Windows 10 и Linux (для остальных ОС - не гарантирую)
- Для запуска необходимо иметь на диске не меньше 35ГБ свободного места. Рекомендуется иметь 50ГБ свободного места и больше

### Настройка переменных окружения

Переименуйте файл `.env.example` (в папке `backend`) в `.env` и замените там значения переменных под ваши нужды

*Если будете менять порт в переменной `FRONTEND_URL` и запускаться из докер контейнера, то его (порт) также нужно будет изменить в докерфайле и в команде запуска контейнера!* 

#### Как получить данные для SMTP клиента

Буду показывать на примере `smtp.gmail.com`

- Вам нужен аккаунт google с включенной двухфакторной авторизацией
- Перейдите в `Управление аккаунтом Google`
- В `Поиск в аккаунте Google` введите `Пароли приложений` и перейдите туда
- Создайте приложение. Введите название (какое угодно) и вам выдадут пароль вида `xxxx xxxx xxxx xxxx`. скопируйте его.
- Перейдите в `backend\.env` файл проекта
- В значение переменной `SMTP_EMAIL` записывайте почту Вашего Google аккаунта на который вы только что создали приложение
- В переменную `SMTP_PASSWORD` запишите скопированный пароль без пробелов. Например: `aaaabbbbccccdddd`
- Значение `SMTP_HOSTNAME` оставьте `smtp.gmail.com`
- Готово!

### Сборка и запуск внутри докер контейнера (рекомендуется)

*На устройстве должен быть установлен docker*

- В терминале перейдите в дикерторию backend/
- Соберите докер образ: `docker build -t your-image-name .`
- В первый раз может собираться довольно долго, так как будет установлено несколько тяжёлых библиотек
- Создайте пустую папку с названием `whisper-large-v3` по следующему пути:
```
Individual-Graduation-Project
└── backend
    └── ai_models                   # Если этой папки нет - создайте
        └── audio2text              # Если этой папки нет - создайте
            └── whisper-large-v3    # Ваша цель - создание этой папки
```
- Скопируйте абсолютный путь до только что созданной вами папки `whisper-large-v3`. Например: `/D/dir1/dir2/Individual-Graduation-Project/backend/ai_models/audio2text/whisper-large-v3` (Здесь `D` - это диск. Важно написать путь до файла именно так, а не, например, так: `D:\dir1\dir2\...`)
- Запустите контейнер: `docker run -v {ваш путь до папки whisper-large-v3}:/app/ai_models/audio2text/whisper-large-v3 --rm -it -p 8000:8000 your-image-name`

- Пример команды: `docker run -v /D/dir1/dir2/Individual-Graduation-Project/backend/ai_models/audio2text/whisper-large-v3:/app/ai_models/audio2text/whisper-large-v3 --rm -it -p 8000:8000 your-image-name`
- Если вы запускаетесь в первый раз, то начнётся довольно долгий процесс скачивания ML модели(ей). Все файлы модели(ей) в сумме весят около 24ГБ (на текущий момент). После того как модель(и) будет(ут) установлена(ы) - бэкенд начнёт свою работу. По умолчанию слушается порт 8000


### Запуск .py файла

Если вы не хотите запускаться в докере, то вам придётся ручками ставить все зависимости и ML модели

#### Установка всех зависимостей

Что нужно установить перед запуском:
- На ПК должен быть установлен Python версии 3.9 и выше
- ffmpeg (установить и добавить в PATH) (гугл в помощь)
- Библиотеки из requirements.txt: в терминале перейдите в директорию `backend/` и выполните команду: `pip install -r requirements.txt`
- Модель whisper-large-v3 в следующую директорию:

```
Individual-Graduation-Project
└── backend
    └── ai_models
        └── audio2text
            └── whisper-large-v3  # Здесь должны быть файлы модели
```
- Чтобы это сделать откройте терминал и перейдите в директорию `backend/`
- Выполните следующую команду: `huggingface-cli download openai/whisper-large-v3 --local-dir ai_models/audio2text/whisper-large-v3`
- По окончанию модель будет установлена на ваш ПК

#### Запуск

- В терминале перейдите в директорию `backend/src/`
- Выполните команду `py main.py`

### После запуска

- Готово. Сервер запущен. Можете перейти в браузере по ссылке `http://localhost:8000/docs` и потыкаться в эндпоинты

